{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_for_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liperdio/liperdio.github.io/blob/master/MLP_for_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24mgFn4gLrYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S39h0biqL6CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# numpy package\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Flatten, Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-boK8ZZFC12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Cifar10 dataset\n",
        "(x_train, y_train_), (x_test, y_test_) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6INZyeGq7bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Resize\n",
        "x_train = np.reshape(x_train, [50000, 32*32*3])\n",
        "x_test = np.reshape(x_test, [10000, 32*32*3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m251f7don_kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute the number of labels\n",
        "num_labels = len(np.unique(y_train_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsiB44raFFmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfQthIXWFHmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert to one-hot vector\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zzXAY28MhGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Network Parameters\n",
        "batch_size = 128\n",
        "hidden_units = 256\n",
        "\n",
        "kernel_regularizer = l2(0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yB-zxSpFJQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A Dense-dense-dense-dense-activation model \n",
        "from keras.models import Sequential\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCcv7UkFLete",
        "colab_type": "code",
        "outputId": "3415c25f-c467-4bd6-b0b5-dcbcd4200909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "\n",
        "model.add(Dense(hidden_units,\n",
        "                kernel_regularizer=kernel_regularizer,\n",
        "                input_dim=3072))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(hidden_units,\n",
        "                kernel_regularizer=kernel_regularizer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(hidden_units,\n",
        "                kernel_regularizer=kernel_regularizer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_labels))\n",
        "# this is the output for one-hot vector\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 256)               786688    \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 920,842\n",
            "Trainable params: 920,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApPAlvDBQdqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use of adam optimizer\n",
        "#loss function for one-hot vector\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjsOlQypFfOo",
        "colab_type": "code",
        "outputId": "ad1acd8d-1312-4313-822e-748beed988a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "# train the network\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=20)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 1.9264 - acc: 0.3263\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.7083 - acc: 0.4052\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 1.6130 - acc: 0.4375\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.5535 - acc: 0.4561\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.5178 - acc: 0.4726\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 1.4811 - acc: 0.4873\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.4553 - acc: 0.4922\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 1.4330 - acc: 0.5054\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 1.4104 - acc: 0.5141\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 1.3852 - acc: 0.5215\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 1.3676 - acc: 0.5285\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.3447 - acc: 0.5400\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.3300 - acc: 0.5469\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 1.3083 - acc: 0.5512\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.2847 - acc: 0.5627\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.2782 - acc: 0.5681\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.2545 - acc: 0.5760\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 1.2358 - acc: 0.5841\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 1.2216 - acc: 0.5901\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 1.2094 - acc: 0.5931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoahyiFZFg0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5e9a7151-56ca-4e1c-cf04-9af83abee86b"
      },
      "source": [
        "# validate the model on the test dataset to determine generalization\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 64us/step\n",
            "\n",
            "Test accuracy: 51.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl9HniHAPHGQ",
        "colab_type": "text"
      },
      "source": [
        "The dataset used for the experiment is the CIFAR10 dataset which consists of 50,000 32x32 pixel color training images, labeled over 10 categories, and 10,000 test images.\n",
        "\n",
        "MLP has the characteristic of fully connected layers, where each perceptron is connected with every other perceptron. After evaluating MLP model against the data it has never seen before (test set), it achieved an accuracy of 51.7%. The low accuracy shows one of the disadvantages of MLP for images which is that it disregards spatial information as it takes flattened vector as inputs.\n",
        "\n",
        "On the other hand, CNN allows panning of filters which enables parameter and weight sharing, where the filter could find a specific pattern anywhere in the image. CNN layers are sparsely connected rather than fully connected. After evaluation against the test set, achieving 73.8% accuracy shows that CNN has a sheer conservation of dimensional data which is very crucial in recognizing images such as CIFAR10 dataset.\n",
        "\n",
        "MLP could be used on the CIFAR10 dataset, but the CNN is more suited for the experiment."
      ]
    }
  ]
}